{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "289ffe15",
   "metadata": {},
   "source": [
    "First, let's load some libraries, load a pig tensor, and create a noise tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b102d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from pickle import loads, dumps\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import json\n",
    "\n",
    "with open(\"imagenet_class_index.json\") as f:\n",
    "    imagenet_classes = {int(i): x[1] for i, x in json.load(f).items()}\n",
    "\n",
    "pig_img = Image.open(\"pig.jpg\")\n",
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "pig_tensor = preprocess(pig_img)[None, :, :, :]\n",
    "gaussian_noise_tensor = torch.randn(1, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b21bd8d",
   "metadata": {},
   "source": [
    "Next, let's load the model and create some target classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b25f9bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple Module to normalize an image\n",
    "class Normalize(torch.nn.Module):\n",
    "    def __init__(self, mean, std):\n",
    "        super(Normalize, self).__init__()\n",
    "        self.mean = torch.Tensor(mean)\n",
    "        self.std = torch.Tensor(std)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return (x - self.mean.type_as(x)[None, :, None, None]) / self.std.type_as(x)[\n",
    "            None, :, None, None\n",
    "        ]\n",
    "\n",
    "\n",
    "norm = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "model.eval()\n",
    "\n",
    "epsilon = 2.0 / 255\n",
    "target_classes = [\n",
    "    49,\n",
    "    272,\n",
    "    276,\n",
    "    286,\n",
    "    287,\n",
    "    288,\n",
    "    290,\n",
    "    291,\n",
    "    292,\n",
    "    293,\n",
    "    340,\n",
    "    344,\n",
    "    366,\n",
    "    367,\n",
    "    372,\n",
    "    386,\n",
    "]\n",
    "target_class_names = [imagenet_classes[cls] for cls in target_classes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74250ad",
   "metadata": {},
   "source": [
    "Next, define the PGD algorithm and a function to plot stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a99a466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd(image, target_classes, file_name, epsilon=epsilon, lr=1e-1, threshold=0.9):\n",
    "    try:\n",
    "        with open(file_name, \"rb\") as f:\n",
    "            return loads(f.read())\n",
    "    except FileNotFoundError:\n",
    "        deltas = []\n",
    "        iters = []\n",
    "\n",
    "        for cls in target_classes:\n",
    "            delta = torch.zeros_like(image, requires_grad=True)\n",
    "            opt = torch.optim.SGD([delta], lr=lr)\n",
    "            # opt = torch.optim.Adam([delta], lr=lr)\n",
    "            step = 0\n",
    "            prob = 0\n",
    "\n",
    "            while prob < threshold:\n",
    "                pred = model(norm((image + delta).clip(0, 1)))\n",
    "                prob = torch.nn.Softmax(dim=1)(pred)[0][cls].item()\n",
    "                print(f\"Class: {cls} Prob: {prob} Step: {step}\")\n",
    "                loss = torch.nn.CrossEntropyLoss()(\n",
    "                    pred,\n",
    "                    torch.LongTensor([cls])\n",
    "                )\n",
    "\n",
    "                opt.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                delta.data.clamp_(-epsilon, epsilon)\n",
    "\n",
    "                step += 1\n",
    "\n",
    "            deltas.append(delta)\n",
    "            iters.append(step)\n",
    "\n",
    "        with open(file_name, \"wb\") as f:\n",
    "            f.write(dumps((deltas, iters)))\n",
    "\n",
    "        return deltas, iters\n",
    "\n",
    "\n",
    "def plot(images, target_class_names, file_name=None):\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(6, 8))\n",
    "    for i, (image, target_class) in enumerate(zip(images, target_class_names)):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        plt.title(f\"{target_class.lower().replace('_', ' ')}\")\n",
    "        plt.imshow(image, cmap=\"gray\")\n",
    "    plt.tight_layout()\n",
    "    if file_name:\n",
    "        plt.savefig(file_name, transparent=True)\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c364ad",
   "metadata": {},
   "source": [
    "Attack and plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac39edd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 49 Prob: 0.0006990268593654037 Step: 0\n",
      "Class: 49 Prob: 0.0012487226631492376 Step: 1\n",
      "Class: 49 Prob: 0.0017028694273903966 Step: 2\n",
      "Class: 49 Prob: 0.0019656638614833355 Step: 3\n",
      "Class: 49 Prob: 0.002621763851493597 Step: 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mpgd\u001b[1;34m(image, target_classes, file_name, epsilon, lr, threshold)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m loads(f\u001b[38;5;241m.\u001b[39mread())\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'targeted_attack_pig_deltas_iters'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m deltas, iters \u001b[38;5;241m=\u001b[39m \u001b[43mpgd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpig_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtargeted_attack_pig_deltas_iters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m plot(\n\u001b[0;32m      3\u001b[0m     [(pig_tensor \u001b[38;5;241m+\u001b[39m a)\u001b[38;5;241m.\u001b[39mclip(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      4\u001b[0m      \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m deltas],\n\u001b[0;32m      5\u001b[0m     target_class_names,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpig_misclassified.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mclf()\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mpgd\u001b[1;34m(image, target_classes, file_name, epsilon, lr, threshold)\u001b[0m\n\u001b[0;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()(\n\u001b[0;32m     21\u001b[0m     pred,\n\u001b[0;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mLongTensor([\u001b[38;5;28mcls\u001b[39m])\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     25\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 26\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     28\u001b[0m delta\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mclamp_(\u001b[38;5;241m-\u001b[39mepsilon, epsilon)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "deltas, iters = pgd(pig_tensor, target_classes, \"targeted_attack_pig_deltas_iters\")\n",
    "plot(\n",
    "    [(pig_tensor + a).clip(0, 1)[0].detach().numpy().transpose(1, 2, 0)\n",
    "     for a in deltas],\n",
    "    target_class_names,\n",
    "    \"pig_misclassified.png\"\n",
    ")\n",
    "plt.clf()\n",
    "plt.imshow((deltas[0][0] * 50).detach().numpy().transpose(1, 2, 0))\n",
    "plt.savefig('delta')\n",
    "print(deltas[0].norm()) # Lower norm probably due to lower learning rate\n",
    "\n",
    "deltas, iters = pgd(\n",
    "    gaussian_noise_tensor,\n",
    "    target_classes,\n",
    "    \"targeted_attack_gaussian_noise_deltas_iters\",\n",
    "    epsilon=1,\n",
    "    lr=10, # Set lr=1 for uniformly distributed noise\n",
    ")\n",
    "plot(\n",
    "    [\n",
    "        (gaussian_noise_tensor + a).clip(0, 1)[0]\n",
    "        .detach().numpy().transpose(1, 2, 0)\n",
    "        for a in deltas\n",
    "    ],\n",
    "    target_class_names,\n",
    "    \"gaussian_noise_misclassified.png\"\n",
    ")\n",
    "print(deltas[0].norm()) # Higher norm probably due to higher learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe98632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
